# Emlinh Remotion - AI Video Generation Platform

Advanced video generation platform combining Remotion and lip-sync technology for creating dynamic, personalized video content.

## ğŸŒŸ Features

- **Audio Integration**: Support for external audio files
- **Realistic Lip-Sync**: Rhubarb-based mouth movement generation
- **Dynamic Compositions**: Remotion-powered video rendering
- **MCP Integration**: Seamless Model Context Protocol support
- **Real-time Preview**: Live development server with hot reload
- **Customizable Avatars**: Flexible character and scene management

## ğŸ“ Project Structure

```
emlinh-remotion/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ components/        # Remotion components
â”‚   â”œâ”€â”€ compositions/      # Video compositions
â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”œâ”€â”€ utils/            # Utility functions
â”‚   â””â”€â”€ types/            # TypeScript definitions
â”œâ”€â”€ tests/                # Test suites
â”‚   â”œâ”€â”€ unit/            # Unit tests
â”‚   â””â”€â”€ integration/     # Integration tests
â”œâ”€â”€ config/              # Configuration files
â”‚   â”œâ”€â”€ remotion.config.ts  # Remotion settings
â”‚   â”œâ”€â”€ tsconfig.json      # TypeScript config
â”‚   â”œâ”€â”€ eslint.config.mjs  # ESLint rules
â”‚   â””â”€â”€ mcp-config.json    # MCP integration
â”œâ”€â”€ docs/                # Documentation
â”‚   â”œâ”€â”€ 01-overview/     # Project overview
â”‚   â”œâ”€â”€ 02-api/          # API documentation
â”‚   â”œâ”€â”€ 03-development/  # Development guides
â”‚   â””â”€â”€ 04-user-guides/  # User manuals
â”œâ”€â”€ public/              # Static assets
â””â”€â”€ output/              # Rendered videos
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ and npm
- FFmpeg installed and in PATH
- MCP Server running (see `../mcp-server/`)

### Installation

```bash
# Install dependencies
npm install

# Setup MCP Server
cd ../mcp-server
cp config/environment/.env.example .env
nano .env  # Configure your API keys

# Start MCP Server
npm run dev
```

### Development

```bash
# Start Remotion development server
npm start

# Preview compositions
npm run preview

# Render video
npm run render
```

## ğŸ¬ Creating Videos

### Basic Text-to-Video

```javascript
import { Composition } from 'remotion';
import { VideoComposition } from './src/compositions/VideoComposition';

export const RemotionRoot = () => {
  return (
    <Composition
      id="main-video"
      component={VideoComposition}
      durationInFrames={300}
      fps={30}
      width={1920}
      height={1080}
      defaultProps={{
        text: "Hello, this is an AI-generated video!",
        voice: "alloy",
        avatar: "default"
      }}
    />
  );
};
```

### Advanced Lip-Sync Video

```javascript
import { LipSyncComposition } from './src/compositions/LipSyncComposition';

const props = {
  audioUrl: "/audio/narration.wav",
  lipsyncData: "/lipsync/narration.json",
  avatar: {
    character: "emma",
    background: "office",
    emotions: ["happy", "excited"]
  }
};
```

## ğŸ”§ Configuration

### Remotion Settings

Edit `config/remotion.config.ts`:

```typescript
import { Config } from '@remotion/cli/config';

Config.setImageFormat('jpeg');
Config.setVideoImageFormat('jpeg');
Config.setOverwriteOutput(true);
Config.setPixelFormat('yuv420p');
Config.setConcurrency(4);
```

### MCP Integration

Configure `config/mcp-config.json`:

```json
{
  "server": {
    "url": "http://localhost:3000",
    "timeout": 30000
  },
  "features": {
    "audio": true,
    "lipsync": true,
    "rendering": true
  }
}
```

## ğŸ§ª Testing

```bash
# Run all tests
npm test

# Unit tests only
npm run test:unit

# Integration tests
npm run test:integration

# Test with coverage
npm run test:coverage
```

## ğŸ“š API Reference

### Core Components

- **`VideoComposition`**: Video generation with audio integration
- **`LipSyncComposition`**: Lip-sync enabled videos
- **`AvatarComponent`**: Customizable character rendering
- **`SceneComponent`**: Background and environment management

### Hooks

- **`useAudioData`**: Audio file processing and analysis
- **`useLipSyncData`**: Lip-sync data management
- **`useBlinkLogic`**: Natural blinking animations
- **`useEmotions`**: Facial expression control

### Utilities

- **`LipSyncResolver`**: Mouth shape calculation
- **`AudioProcessor`**: Audio file manipulation
- **`SceneManager`**: Scene transition handling

## ğŸ¨ Customization

### Adding New Avatars

1. Create avatar assets in `public/avatars/`
2. Define avatar configuration in `src/types/avatar.ts`
3. Implement avatar component in `src/components/avatars/`
4. Register in `src/utils/avatar-registry.ts`

### Custom Compositions

1. Create composition file in `src/compositions/`
2. Export from `src/Root.tsx`
3. Add to Remotion registry
4. Configure default props

## ğŸš€ Deployment

### Render Videos

```bash
# Render specific composition
npm run render -- --id="my-composition"

# Batch render
npm run render:batch

# Cloud rendering (if configured)
npm run render:cloud
```

### Production Build

```bash
# Build for production
npm run build

# Serve built files
npm run serve
```

## ğŸ¤ Contributing

1. Follow the project structure guidelines
2. Write comprehensive tests for new features
3. Update documentation for API changes
4. Follow TypeScript and React best practices
5. Test with multiple avatar and voice combinations

## ğŸ“– Documentation

- [Project Overview](./docs/01-overview/)
- [API Documentation](./docs/02-api/)
- [Development Guide](./docs/03-development/)
- [User Guides](./docs/04-user-guides/)

## ğŸ“„ License

MIT License - see LICENSE.md for details

## ğŸ†˜ Support

For issues and questions:
1. Check the [FAQ](./docs/04-user-guides/faq.md)
2. Review [Troubleshooting Guide](./docs/04-user-guides/troubleshooting.md)
3. Open an issue on GitHub

---

**Built with â¤ï¸ using Remotion, React, and AI technologies**
